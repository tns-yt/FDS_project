{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fU3HuTjYkWd5"
   },
   "source": [
    "Ques 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5d793c1f"
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1b746e3e"
   },
   "outputs": [],
   "source": [
    "def resize_image(input_path, output_path, scale_factor):\n",
    "    try:\n",
    "        # Open the image file\n",
    "        original_image = Image.open(input_path)\n",
    "\n",
    "        # Get the original size of the image\n",
    "        original_size = original_image.size\n",
    "\n",
    "        # Calculate the new size based on the scale factor\n",
    "        new_size = tuple(int(dim * scale_factor) for dim in original_size)\n",
    "\n",
    "        # Resize the image\n",
    "        resized_image = original_image.resize(new_size)\n",
    "\n",
    "        # Save the resized image to the specified output path\n",
    "        resized_image.save(output_path)\n",
    "\n",
    "        print(f\"Image resized and saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "16d52062",
    "outputId": "cd3fb224-7992-4f3e-ced5-d37b00486039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the input image file (with extension): n\n",
      "Error: [Errno 2] No such file or directory: 'n'\n",
      "Error: [Errno 2] No such file or directory: 'n'\n",
      "Error: [Errno 2] No such file or directory: 'n'\n"
     ]
    }
   ],
   "source": [
    "# Get user input for the image file name\n",
    "input_image_path = input(\"Enter the name of the input image file (with extension): \")\n",
    "\n",
    "# Resize to 30%\n",
    "resize_image(input_image_path, 'resized_30.jpg', 0.3)\n",
    "\n",
    "# Resize to 60%\n",
    "resize_image(input_image_path, 'resized_60.jpg', 0.6)\n",
    "\n",
    "# Resize to 90%\n",
    "resize_image(input_image_path, 'resized_90.jpg', 0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sP42VWPrnZSy"
   },
   "source": [
    "Ques 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xMtcFBrvln3z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import eigh\n",
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "417fbac7",
    "outputId": "f758ffce-b125-4ee9-ef1d-8582322e4290"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/libras Movement.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/libras Movement.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/libras Movement.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('libras Movement.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ced56c60",
    "outputId": "c72d2186-6135-40ee-ba9a-fc9c715a664e"
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7e038b2b"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cceb0f3"
   },
   "source": [
    "There are no null values in the give data frame,so no need of cleaning of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59b61996"
   },
   "outputs": [],
   "source": [
    "Y=data[data.columns[-1]]\n",
    "data.drop([data.columns[-1]],axis=1,inplace=True)#last column is target variable on which PDA whould not be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f25e0ca3",
    "outputId": "65ee92e2-c098-4411-8ff1-76d42ba1ae3d"
   },
   "outputs": [],
   "source": [
    "arr_data = data.values\n",
    "arr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cf6aacf",
    "outputId": "5972b8bf-e5ca-498f-d7e3-7762af52d237"
   },
   "outputs": [],
   "source": [
    "arr_data_m = np.mean(arr_data,axis=0)\n",
    "arr_data_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c1f797b",
    "outputId": "58fc132c-0d2f-4026-e5b1-d87a03f3016c"
   },
   "outputs": [],
   "source": [
    "#calculating covariance matrix\n",
    "cent = arr_data-arr_data_m#don't confuse with unmatching of dimension,broadcasting occurs\n",
    "cov = (1/len(cent))*(cent.T@cent)#fromula of covariance matrix\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "224c4ea8",
    "outputId": "64fba7bf-bb3c-42c0-c3c4-f557b08853e2"
   },
   "outputs": [],
   "source": [
    "eigval, eigvec = eigh(cov)\n",
    "print(eigvec.shape)\n",
    "idx = eigval.argsort()[::-1]#getting decreasing order of eigen values\n",
    "eigval = eigval[idx]#sorting sorting eigen vectors in decreasing arder according to eigen values\n",
    "eigvec = eigvec[:,idx]\n",
    "eigvec\n",
    "#print(len(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f475a145"
   },
   "outputs": [],
   "source": [
    "#run the following cells to verify that principal components are orthogonoal to each other.\n",
    "#(i am commenting this because,this will many lines and not neccessary)\n",
    "'''for i in range(0,len(eigvec[0])-1):\n",
    "    for j in range(0,len(eig[0])-1):\n",
    "        if i!=j:\n",
    "            print(float(np.dot(eigvec[:,i],eigvec[:,j])))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "746a5813"
   },
   "source": [
    "covariance captured in a dimension(in one of eigen vector) is propotional to eigen value.So, we have to find number of eigen vectors to be used to get desired percentage of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63b93fc2",
    "outputId": "c3c84b56-683c-4d3c-b95f-c329fa72d6e7"
   },
   "outputs": [],
   "source": [
    "#to know which componenents capture how much variance:(for first 10 components)\n",
    "Q = sum(eigval)\n",
    "for i in range(10):\n",
    "    print('Percentage of variance captured by {}th principal component: {} '.format(i,(eigval[i]/Q)*100)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94f203e0"
   },
   "outputs": [],
   "source": [
    "def dim(eigval,ratio):#assuming that 0 is not given in ratio\n",
    "    ind,temp_sum,total = 0,eigval[0],np.sum(eigval)\n",
    "    for ind in range(1,len(eigval)):\n",
    "        if temp_sum/total>=ratio:break\n",
    "        else:\n",
    "            temp_sum+=eigval[ind]\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfcf1518"
   },
   "source": [
    "dim(eigval,0.95)=9#requires minimum of 9 dimesnion to captue 95 % of covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08c82cd5"
   },
   "source": [
    "Applying PCA by projecting centered data and original data onto required number of eigen vectors,depending on required percentage of variance to be captured).I am using minimum number of dimensions that should be used to capture required amount of variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e796584",
    "outputId": "712f9a75-ab4e-4e52-b99a-5edd4a27c94b"
   },
   "outputs": [],
   "source": [
    "#1:For 60% data\n",
    "d = dim(eigval,60/100)\n",
    "print(d)\n",
    "e_vector = eigvec[0:d,:]\n",
    "pca_data_60 = cent@e_vector.T\n",
    "pca_data_60_X = arr_data@e_vector.T\n",
    "pca_data_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65d7ea59",
    "outputId": "f43558da-d537-4c08-ec20-f0c4015e604d"
   },
   "outputs": [],
   "source": [
    "#1:For 75% data\n",
    "d = dim(eigval,75/100)\n",
    "print(d)\n",
    "e_vector = eigvec[0:d,:]\n",
    "pca_data_75 = cent@e_vector.T\n",
    "pca_data_75_X = arr_data@e_vector.T\n",
    "pca_data_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4c7d491",
    "outputId": "3febd6f5-a168-4266-c627-b34ba93f1a3b"
   },
   "outputs": [],
   "source": [
    "#1:For 90% data\n",
    "d = dim(eigval,90/100)\n",
    "print(d)\n",
    "e_vector = eigvec[0:d,:]\n",
    "pca_data_90 = cent@e_vector.T#projecting centered data\n",
    "pca_data_90_X = arr_data@e_vector.T#projecting original data\n",
    "pca_data_90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2705d6b9"
   },
   "source": [
    "Final Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7e29eec4"
   },
   "outputs": [],
   "source": [
    "pca_df_60,pca_df_75,pca_df_90 = pd.DataFrame(pca_data_60),pd.DataFrame(pca_data_75),pd.DataFrame(pca_data_90)#for centered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0c746b39"
   },
   "outputs": [],
   "source": [
    "pca_df_60_X,pca_df_75_X,pca_df_90_X = pd.DataFrame(pca_data_60_X),pd.DataFrame(pca_data_75_X),pd.DataFrame(pca_data_90_X)#for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6eb5cde"
   },
   "outputs": [],
   "source": [
    "U,S,Vt = svd(data)\n",
    "mat_S =np.diag(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9e4e9c89",
    "outputId": "26507a17-726a-45d9-f332-41a91bc08f8e"
   },
   "outputs": [],
   "source": [
    "print(np.sum((S)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e332ff83",
    "outputId": "4b88948a-fb00-4771-f873-fe9eae24e146"
   },
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    print( 'Percentage of variance explained by {}th component: {}'.format( i, (S[i]**2)/np.sum(np.square(S))*100 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afb86e38"
   },
   "outputs": [],
   "source": [
    "def req_dim(S,ratio):\n",
    "    tot = np.sum(np.square(S))\n",
    "    acq_sum = S[0]**2#acquired sum till now..\n",
    "    ind = 0\n",
    "    for ind in range(1,len(S)):\n",
    "        if acq_sum/tot >= ratio:break#acq_sum is num upto ind-1\n",
    "        else:\n",
    "            acq_sum+=S[ind]**2\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "710f7d8b"
   },
   "outputs": [],
   "source": [
    "#for 60%:\n",
    "per = 60\n",
    "s_60=req_dim(S,per/100)#required number of singular values\n",
    "svd_data_60 = U[:,:s_60]@mat_S[:s_60,:s_60]@Vt[:s_60,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2aad2eb"
   },
   "outputs": [],
   "source": [
    "#for 75%:\n",
    "per = 75\n",
    "s_75=req_dim(S,per/100)\n",
    "svd_data_75 = U[:,:s_75]@mat_S[:s_75,:s_75]@Vt[:s_75,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8a69757"
   },
   "outputs": [],
   "source": [
    "#for 90%:\n",
    "per = 90\n",
    "s_90=req_dim(S,per/100)\n",
    "svd_data_90 = U[:,:s_90]@mat_S[:s_90,:s_90]@Vt[:s_90,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12e799ac"
   },
   "outputs": [],
   "source": [
    "svd_df_60,svd_df_75,svd_df_90 = pd.DataFrame(svd_data_60),pd.DataFrame(svd_data_75),pd.DataFrame(svd_data_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svd_df_60,svd_df_75,svd_df_90,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9978602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c59a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF,DF_X = pca_df_60,pca_df_60_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6584a5",
   "metadata": {},
   "source": [
    "Knowing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6025eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DF.info(),DF_X.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2801c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DF.describe(),DF_X.describe(),sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ba181",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14bf6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(DF_X,kind='reg',diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e2b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(DF_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8285e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = DF_X.corr()\n",
    "sns.heatmap(cor,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avnNAr_rllD3"
   },
   "source": [
    "Ques 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgZWrBQylKP0"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-1YG-KslKP3"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Diabetes.csv')\n",
    "x= data.iloc[:,1:-1].values\n",
    "y= data.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoWQO8nhlKP5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest= train_test_split(x,y,random_state=0,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXsc7BuvlKP5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "xtrain =sc.fit_transform(xtrain)\n",
    "xtest= sc.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkzj8fqLlKP6"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT_classifier= DecisionTreeClassifier(criterion='entropy')\n",
    "DT_classifier.fit(xtrain,ytrain)\n",
    "ypred= DT_classifier.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkUKRfNUlKP6",
    "outputId": "de9f7edc-9d7c-456e-a334-3caf9f82f3f3"
   },
   "outputs": [],
   "source": [
    "cm_dt= confusion_matrix(ytest,ypred)\n",
    "as_dt= accuracy_score(ytest,ypred)\n",
    "print(cm_dt)\n",
    "print(as_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuIpMu_wlKP7"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_classifier= RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "RF_classifier.fit(xtrain,ytrain)\n",
    "ypred_rf= RF_classifier.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBn0HVrIlKP8",
    "outputId": "3958a6f9-b835-4ad1-abd9-48e83c0f5ab2"
   },
   "outputs": [],
   "source": [
    "cm_rf= confusion_matrix(ytest,ypred_rf)\n",
    "as_rf= accuracy_score(ytest,ypred_rf)\n",
    "print(cm_rf)\n",
    "print(as_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWAuErN4lKP9"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN_classifier= KNeighborsClassifier(n_neighbors=8, metric='minkowski')\n",
    "KNN_classifier.fit(xtrain,ytrain)\n",
    "ypred_knn= KNN_classifier.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSdfTgsslKP9",
    "outputId": "82ea4770-589f-4407-eb2e-3a8cf7d42f5b"
   },
   "outputs": [],
   "source": [
    "cm_knn= confusion_matrix(ytest,ypred_knn)\n",
    "as_knn= accuracy_score(ytest, ypred_knn)\n",
    "print(cm_knn)\n",
    "print(as_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDl9N3CcngSr"
   },
   "source": [
    "Ques 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgOETWEAKg46"
   },
   "source": [
    "# *Importing the Important Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjYVxs-5Kg5B"
   },
   "outputs": [],
   "source": [
    "#Importing the libraries we would neeed in the code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEf0S2SrKg5E"
   },
   "source": [
    "# *Importing the Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJApnFSEKg5F"
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv('OJ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "ZUW3dQ5-Kg5F",
    "outputId": "0b1ef2d2-126d-4b3f-b215-7e10f2e69a8c"
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLXRE1B5Kg5H"
   },
   "source": [
    "## *Encoding the Data and Setting the Data Types*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-V6pBbAJKg5H"
   },
   "outputs": [],
   "source": [
    "#Encoding the data values that at non-integers like the Purchase column and Store7 column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le= LabelEncoder()\n",
    "data['Purchase']= le.fit_transform(data['Purchase'])\n",
    "data['Store7']=le.fit_transform(data['Store7'])\n",
    "\n",
    "data= data.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "LQXD-Y6TKg5H",
    "outputId": "6084ddb4-57dd-4760-d989-f2a5ab8a8467"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-m7T77qKg5I",
    "outputId": "5171730f-16c0-4036-d3ba-cf53c78cec7e"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7sFgVA7Kg5I"
   },
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "12wpDeZvKg5J",
    "outputId": "56ea1ccf-61c5-41ef-81d2-a542f0182adf"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 933
    },
    "id": "InvM7ZjtKg5J",
    "outputId": "037ed128-57bf-4718-cc89-997d62139737"
   },
   "outputs": [],
   "source": [
    "data.hist(figsize=(18,15))\n",
    "plt.suptitle('Histogram of Features',y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 858
    },
    "id": "5Ksjet1zKg5J",
    "outputId": "4300d486-38d9-4029-b282-7e9d0014b45b"
   },
   "outputs": [],
   "source": [
    "corr_matrix= data.corr()\n",
    "plt.figure(figsize=(25,20))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G1yJu5TKg5K"
   },
   "source": [
    "# *Splitting the Data into Train and Test Sets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJb5AIcEKg5K"
   },
   "outputs": [],
   "source": [
    "x=data.iloc[:,1:].values\n",
    "y=data.iloc[:,0].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHdqpqqKKg5L"
   },
   "source": [
    "## **Using PCA to Drop the Highly Correlated Columns in the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHwvBK2nKg5L"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "xtrain_pca = pca.fit_transform(xtrain)\n",
    "\n",
    "# Get the explained variance ratio for each principal component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Identify the principal components that contribute most to the explained variance\n",
    "significant_components = [i for i, ratio in enumerate(explained_variance_ratio) if ratio > 1e-8]\n",
    "\n",
    "# Select only the columns corresponding to significant principal components\n",
    "xtrain_pca = xtrain_pca[:, significant_components]\n",
    "xtest_pca = pca.transform(xtest)[:, significant_components]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwxJNpr1Kg5M",
    "outputId": "74ab29ba-d789-4873-f794-9775e694a27a"
   },
   "outputs": [],
   "source": [
    "xtrain_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVmeX7shKg5M",
    "outputId": "ff3f29f8-df34-47df-d2a7-e95fd863ecea"
   },
   "outputs": [],
   "source": [
    "explained_variance_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3BukBh1Kg5M"
   },
   "source": [
    "## *Standard Scaling the Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rk8Wf0i-Kg5M"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "xtrain_pca =sc.fit_transform(xtrain_pca)\n",
    "xtest_pca= sc.transform(xtest_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5drd24sLiFK"
   },
   "source": [
    "## **Logistic regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYIrMbX1Kg5N"
   },
   "source": [
    "Using Logistic Regression Model to make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrXdRpcLNOTb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXF02LJtRMmj"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLiB2UA_Kg5N"
   },
   "outputs": [],
   "source": [
    "logistic= LogisticRegression()\n",
    "logistic.fit(xtrain_pca,ytrain)\n",
    "ypred_lr= logistic.predict(xtest_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "wka5SFL0Kg5N",
    "outputId": "f1d601fe-5b14-4f92-8841-63f5a1c6ab81"
   },
   "outputs": [],
   "source": [
    "cm_lr= confusion_matrix(ytest,ypred_lr)\n",
    "print(\"The confusion matrix for logistic regression is \\n\", cm_lr)\n",
    "as_lr= accuracy_score(ytest,ypred_lr)\n",
    "print(\"Accuracy \", as_lr)\n",
    "\n",
    "# Precision, Recall, and F1 Score\n",
    "precision = precision_score(ytest, ypred_lr, average='weighted')\n",
    "recall = recall_score(ytest, ypred_lr, average='weighted')\n",
    "f1 = f1_score(ytest, ypred_lr, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_lr, annot=True, cmap= 'coolwarm',fmt=\"d\")\n",
    "plt.title('Logistic Regression HeatMap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAbFCRThKg5N"
   },
   "source": [
    "# Using Quadratic Discriminant Analysis to make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G35c0EleKg5O"
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda= QuadraticDiscriminantAnalysis()\n",
    "qda.fit(xtrain_pca,ytrain)\n",
    "ypred_qda= qda.predict(xtest_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "J-KfrrIBKg5O",
    "outputId": "cecbb4b5-529f-482b-912b-05df2d166a02"
   },
   "outputs": [],
   "source": [
    "cm_qda= confusion_matrix(ytest,ypred_qda)\n",
    "as_qda= accuracy_score(ytest,ypred_qda)\n",
    "print(\"The confusion matrix for QDA is \\n\", cm_qda)\n",
    "print(\"The accuracy for QDA is \",as_qda)\n",
    "\n",
    "\n",
    "# Precision, Recall, and F1 Score\n",
    "precision = precision_score(ytest, ypred_qda, average='weighted')\n",
    "recall = recall_score(ytest, ypred_qda, average='weighted')\n",
    "f1 = f1_score(ytest, ypred_qda, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_qda, annot=True, cmap= 'coolwarm',fmt=\"d\")\n",
    "plt.title('Quadratic Discriminant Analysis HeatMap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMbMM88nRUwi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
